{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = os.listdir('petfinder-pawpularity-score/train')\n",
    "train_df = pd.read_csv('petfinder-pawpularity-score/train.csv')\n",
    "train_df = train_df.set_index('Id')\n",
    "\n",
    "file_names = []\n",
    "labels = []\n",
    "\n",
    "for index in train_df.index:\n",
    "    file_name = 'petfinder-pawpularity-score/train/' + index + '.jpg'\n",
    "    label = train_df.loc[index]['Pawpularity']\n",
    "    file_names.append(file_name)\n",
    "    labels.append(label/1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, val_files, labels_train, labels_val = train_test_split(file_names, labels, test_size=0.2, random_state=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 10:49:41.349923: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-03-25 10:49:41.349941: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-03-25 10:49:41.349945: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-03-25 10:49:41.349974: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-25 10:49:41.349988: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def process_file_names_train(file_name, label):\n",
    "    image_string = tf.io.read_file(file_name)\n",
    "    img = tf.io.decode_jpeg(image_string, channels=3)\n",
    "    img = tf.image.resize(img, [224,224])\n",
    "    img = img/255.\n",
    "    # drop this for val data\n",
    "    img = tf.image.resize_with_crop_or_pad(img, 224 + 6, 224 + 6)\n",
    "    # Random crop back to the original size.\n",
    "    image = tf.image.random_crop(\n",
    "      img, size=[224, 224, 3])\n",
    "    # Random brightness.\n",
    "    image = tf.image.random_brightness(\n",
    "      image, max_delta=0.5)\n",
    "    image = tf.clip_by_value(image, 0, 1)\n",
    "    # rescale labels so between 0 and 1\n",
    "    return image, label/100.01\n",
    "\n",
    "def process_file_names_val(file_name, label):\n",
    "    image_string = tf.io.read_file(file_name)\n",
    "    img = tf.io.decode_jpeg(image_string, channels=3)\n",
    "    img = tf.image.resize(img, [224,224])\n",
    "    img = img/255.\n",
    "    # rescale labels so between 0 and 1\n",
    "    return img, label/100.01\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_files, labels_train))\n",
    "train_dataset = train_dataset.map(process_file_names_train)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_files, labels_val))\n",
    "val_dataset = val_dataset.map(process_file_names_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(32)\n",
    "    return ds\n",
    "\n",
    "train_dataset = configure_for_performance(train_dataset)\n",
    "\n",
    "val_dataset = configure_for_performance(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "248/248 [==============================] - 234s 922ms/step - loss: 0.6950 - root_mean_squared_error: 0.2101 - val_loss: 0.6648 - val_root_mean_squared_error: 0.2128\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 231s 930ms/step - loss: 0.6644 - root_mean_squared_error: 0.2044 - val_loss: 0.6648 - val_root_mean_squared_error: 0.2127\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 228s 918ms/step - loss: 0.6644 - root_mean_squared_error: 0.2045 - val_loss: 0.6647 - val_root_mean_squared_error: 0.2127\n",
      "Epoch 4/10\n",
      "  6/248 [..............................] - ETA: 3:32 - loss: 0.6621 - root_mean_squared_error: 0.2104"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m CNN \u001b[39m=\u001b[39m build_cnn()\n\u001b[1;32m     22\u001b[0m \u001b[39m# use early stopping\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m#early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m history \u001b[39m=\u001b[39m CNN\u001b[39m.\u001b[39;49mfit(train_dataset,\n\u001b[1;32m     26\u001b[0m                   epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     27\u001b[0m                   validation_data\u001b[39m=\u001b[39;49mval_dataset,\n\u001b[1;32m     28\u001b[0m                   verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/engine/training.py:1813\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1812\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1813\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1815\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     hook(batch, logs)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnest.map_structure\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_structure\u001b[39m(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[39m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[39m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[39mreturn\u001b[39;00m nest_util\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[1;32m    632\u001b[0m       nest_util\u001b[39m.\u001b[39;49mModality\u001b[39m.\u001b[39;49mCORE, func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    633\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[39m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[39m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[39mif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_core_map_structure(func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1067\u001b[0m \u001b[39melif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    688\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:394\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[1;32m    373\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_course/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:360\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    359\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m    361\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def build_cnn():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=64, kernel_size=5, activation=\"relu\", padding=\"same\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=128, kernel_size=5, activation=\"relu\", padding=\"same\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(tf.keras.layers.Conv2D(\n",
    "        filters=256, kernel_size=5, activation=\"relu\", padding=\"same\"))\n",
    "    #model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "    model.add(tf.keras.layers.GlobalAvgPool2D())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    #model.add(tf.keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.003),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "CNN = build_cnn()\n",
    "# use early stopping\n",
    "#early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "# Train the model\n",
    "history = CNN.fit(train_dataset,\n",
    "                  epochs=10,\n",
    "                  validation_data=val_dataset,\n",
    "                  verbose=1)\n",
    "                  #callbacks=[early_stopping_callback])\n",
    "#test_loss, test_metric = CNN.evaluate(images_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      4864      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 128)     204928    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 256)       819456    \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 256)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1029505 (3.93 MB)\n",
      "Trainable params: 1029505 (3.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define residual layer\n",
    "\n",
    "class ResidualUnit(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            tf.keras.layers.Conv2D(filters, kernel_size=3, strides=strides, padding='same', kernel_initializer='he_normal', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            tf.keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', kernel_initializer='he_normal', use_bias=False),\n",
    "            tf.keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        # If strides > 1 need to use 1D convolutions with long stride to resize image so they can be added\n",
    "        if strides == 1:\n",
    "            self.skip_layers = []\n",
    "        else:\n",
    "            self.skip_layers = [\n",
    "                tf.keras.layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same', kernel_initializer='he_normal', use_bias=False),\n",
    "                tf.keras.layers.BatchNormalization()\n",
    "            ]\n",
    "    def call(self, inputs):\n",
    "        z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            z = layer(z)\n",
    "        skip_z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_z = layer(skip_z)\n",
    "        # either return a(z) + skip_z or a(z + skip_z)\n",
    "        return self.activation(z + skip_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 10:49:55.365470: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 54s 194ms/step - loss: 0.7000 - root_mean_squared_error: 0.2373 - val_loss: 0.9065 - val_root_mean_squared_error: 0.3544\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 43s 173ms/step - loss: 0.6744 - root_mean_squared_error: 0.2181 - val_loss: 0.6829 - val_root_mean_squared_error: 0.2202\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 42s 169ms/step - loss: 0.6685 - root_mean_squared_error: 0.2123 - val_loss: 0.6670 - val_root_mean_squared_error: 0.2011\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 42s 170ms/step - loss: 0.6674 - root_mean_squared_error: 0.2111 - val_loss: 0.6894 - val_root_mean_squared_error: 0.2233\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 43s 172ms/step - loss: 0.6654 - root_mean_squared_error: 0.2089 - val_loss: 0.6657 - val_root_mean_squared_error: 0.1998\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 39s 159ms/step - loss: 0.6629 - root_mean_squared_error: 0.2062 - val_loss: 0.6675 - val_root_mean_squared_error: 0.2018\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 40s 161ms/step - loss: 0.6607 - root_mean_squared_error: 0.2037 - val_loss: 0.6701 - val_root_mean_squared_error: 0.2049\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 38s 154ms/step - loss: 0.6566 - root_mean_squared_error: 0.1988 - val_loss: 0.6931 - val_root_mean_squared_error: 0.2293\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 38s 153ms/step - loss: 0.6531 - root_mean_squared_error: 0.1945 - val_loss: 0.6872 - val_root_mean_squared_error: 0.2198\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6448 - root_mean_squared_error: 0.1841Restoring model weights from the end of the best epoch: 5.\n",
      "248/248 [==============================] - 39s 156ms/step - loss: 0.6448 - root_mean_squared_error: 0.1841 - val_loss: 0.6856 - val_root_mean_squared_error: 0.2224\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "def build_resnet():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same', kernel_initializer='he_normal', use_bias=False, input_shape=[224,224,3]))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same'))\n",
    "    prev_filters = 128\n",
    "    for filters in [64, 64, 128, 256, 512]:\n",
    "        strides = 1 if filters == prev_filters else 2\n",
    "        model.add(ResidualUnit(filters, strides=strides))\n",
    "        prev_filters = filters\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.GlobalAvgPool2D())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    #model.add(tf.keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "resnet = build_resnet()\n",
    "# use early stopping\n",
    "#early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "# Train the model\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "history = resnet.fit(train_dataset,\n",
    "                  epochs=10,\n",
    "                  validation_data=val_dataset,\n",
    "                  verbose=1,\n",
    "                  callbacks=[early_stopping_callback])\n",
    "#test_loss, test_metric = CNN.evaluate(images_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.755687461850368\n",
      "19.91888946933486\n"
     ]
    }
   ],
   "source": [
    "labels_train_array = np.array(labels_train)\n",
    "labels_val_array = np.array(labels_val)\n",
    "train_mean = np.mean(labels_train_array)\n",
    "\n",
    "print(np.sqrt(np.mean(np.square(labels_train_array - train_mean))))\n",
    "print(np.sqrt(np.mean(np.square(labels_val_array - train_mean))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 112, 112, 64)      9408      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 112, 112, 64)      256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 56, 56, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " residual_unit (ResidualUni  (None, 28, 28, 64)        78592     \n",
      " t)                                                              \n",
      "                                                                 \n",
      " residual_unit_1 (ResidualU  (None, 28, 28, 64)        74240     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_2 (ResidualU  (None, 14, 14, 128)       230912    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_3 (ResidualU  (None, 7, 7, 256)         920576    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_4 (ResidualU  (None, 4, 4, 512)         3676160   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 512)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4990144 (19.04 MB)\n",
      "Trainable params: 4984000 (19.01 MB)\n",
      "Non-trainable params: 6144 (24.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "248/248 [==============================] - 72s 275ms/step - loss: 0.7058 - root_mean_squared_error: 0.2316 - val_loss: 0.6884 - val_root_mean_squared_error: 0.2353\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 65s 263ms/step - loss: 0.6811 - root_mean_squared_error: 0.2221 - val_loss: 0.6754 - val_root_mean_squared_error: 0.2247\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 66s 264ms/step - loss: 0.6737 - root_mean_squared_error: 0.2146 - val_loss: 0.7620 - val_root_mean_squared_error: 0.2849\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 66s 265ms/step - loss: 0.6741 - root_mean_squared_error: 0.2149 - val_loss: 0.7315 - val_root_mean_squared_error: 0.2667\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 65s 264ms/step - loss: 0.6705 - root_mean_squared_error: 0.2112 - val_loss: 0.7141 - val_root_mean_squared_error: 0.2547\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 67s 268ms/step - loss: 0.6684 - root_mean_squared_error: 0.2087 - val_loss: 0.6700 - val_root_mean_squared_error: 0.2182\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 66s 265ms/step - loss: 0.6650 - root_mean_squared_error: 0.2049 - val_loss: 0.6949 - val_root_mean_squared_error: 0.2452\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 65s 264ms/step - loss: 0.6642 - root_mean_squared_error: 0.2037 - val_loss: 0.7128 - val_root_mean_squared_error: 0.2525\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 65s 264ms/step - loss: 0.6572 - root_mean_squared_error: 0.1956 - val_loss: 0.6913 - val_root_mean_squared_error: 0.2363\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 66s 266ms/step - loss: 0.6547 - root_mean_squared_error: 0.1923 - val_loss: 0.9105 - val_root_mean_squared_error: 0.3403\n"
     ]
    }
   ],
   "source": [
    "def build_resnet():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same', kernel_initializer='he_normal', use_bias=False, input_shape=[224,224,3]))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same'))\n",
    "    prev_filters = 128\n",
    "    for filters in [64]*3 + [128]*4 + [256]*6 + [512]*3:\n",
    "        strides = 1 if filters == prev_filters else 2\n",
    "        model.add(ResidualUnit(filters, strides=strides))\n",
    "        prev_filters = filters\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.GlobalAvgPool2D())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    #model.add(tf.keras.layers.Dense(units=512, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "resnet = build_resnet()\n",
    "# use early stopping\n",
    "#early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "# Train the model\n",
    "history = resnet.fit(train_dataset,\n",
    "                  epochs=10,\n",
    "                  validation_data=val_dataset,\n",
    "                  verbose=1)\n",
    "                  #callbacks=[early_stopping_callback])\n",
    "#test_loss, test_metric = CNN.evaluate(images_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m resnet\u001b[39m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet' is not defined"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 112, 112, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 56, 56, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 28, 28, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 14, 14, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 7, 7, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134260544 (512.16 MB)\n",
      "Trainable params: 134260544 (512.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def vgg16(input_shape=(224, 224, 3)):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        #tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create VGG16 model\n",
    "vgg16_model = vgg16()\n",
    "\n",
    "# Display model summary\n",
    "vgg16_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('ml_course')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e504829df0f4f270cad31406f14acd3504c0cc9fbc0566e15931d3ba63c9744"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
